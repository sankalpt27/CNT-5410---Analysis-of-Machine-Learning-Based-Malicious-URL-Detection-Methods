{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:51:57.267384Z",
     "iopub.status.busy": "2022-12-06T18:51:57.266827Z",
     "iopub.status.idle": "2022-12-06T18:51:59.098625Z",
     "shell.execute_reply": "2022-12-06T18:51:59.097479Z",
     "shell.execute_reply.started": "2022-12-06T18:51:57.267265Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    " from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sankalp/Documents/URL Code'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:51:59.102884Z",
     "iopub.status.busy": "2022-12-06T18:51:59.102288Z",
     "iopub.status.idle": "2022-12-06T18:52:00.470481Z",
     "shell.execute_reply": "2022-12-06T18:52:00.469601Z",
     "shell.execute_reply.started": "2022-12-06T18:51:59.102842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br-icloud.com.br</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mp3raid.com/music/krizz_kaliko.html</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bopsecrets.org/rexroth/cr/1.htm</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.garage-pirenne.be/index.php?option=...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://adventure-nicaragua.net/index.php?optio...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url        type\n",
       "0                                   br-icloud.com.br    phishing\n",
       "1                mp3raid.com/music/krizz_kaliko.html      benign\n",
       "2                    bopsecrets.org/rexroth/cr/1.htm      benign\n",
       "3  http://www.garage-pirenne.be/index.php?option=...  defacement\n",
       "4  http://adventure-nicaragua.net/index.php?optio...  defacement"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(cwd +'/malicious_phish.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:52:00.472371Z",
     "iopub.status.busy": "2022-12-06T18:52:00.472023Z",
     "iopub.status.idle": "2022-12-06T18:52:00.526260Z",
     "shell.execute_reply": "2022-12-06T18:52:00.525226Z",
     "shell.execute_reply.started": "2022-12-06T18:52:00.472337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Label_Index:\n",
    "    def __init__(self, dataset):\n",
    "        self.labels = dataset['type'].unique()\n",
    "        self.label_index = {label: index for index, label in enumerate(self.labels)}\n",
    "        self.index_label = {index: label for index, label in enumerate(self.labels)}\n",
    "    \n",
    "    def indexes_labels(self, dataset):\n",
    "        return dataset['type'].map(self.index_label)\n",
    "\n",
    "    def labels_indexes(self, dataset):\n",
    "        return dataset['type'].map(self.label_index)\n",
    "    def __call__(self, label):\n",
    "        return self.label_index[label]\n",
    "\n",
    "label_index = Label_Index(dataset)\n",
    "label_index('phishing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:52:00.529394Z",
     "iopub.status.busy": "2022-12-06T18:52:00.528950Z",
     "iopub.status.idle": "2022-12-06T18:52:03.933779Z",
     "shell.execute_reply": "2022-12-06T18:52:03.932842Z",
     "shell.execute_reply.started": "2022-12-06T18:52:00.529358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 6, 10, 9, 0, 1], 333)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Char_Index:\n",
    "    def __init__(self, urls) -> None:\n",
    "        self.char_index = {}\n",
    "        self.index_char = {}\n",
    "        for url in urls:\n",
    "            for char in url:\n",
    "                if char not in self.char_index:\n",
    "                    self.char_index[char] = len(self.char_index)\n",
    "                    self.index_char[len(self.index_char)] = char\n",
    "    \n",
    "    def string_indexes(self, string):\n",
    "        return [self.char_index[char] for char in string]\n",
    "\n",
    "char_index = Char_Index(dataset['url'])\n",
    "char_index.string_indexes(dataset.url[0]), len(char_index.char_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:52:03.935683Z",
     "iopub.status.busy": "2022-12-06T18:52:03.935307Z",
     "iopub.status.idle": "2022-12-06T18:52:04.081364Z",
     "shell.execute_reply": "2022-12-06T18:52:04.080386Z",
     "shell.execute_reply.started": "2022-12-06T18:52:03.935647Z"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split data into train and test\n",
    "train_data = dataset[:int(len(dataset)*0.8)]\n",
    "test_data = dataset[int(len(dataset)*0.8):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:52:04.083431Z",
     "iopub.status.busy": "2022-12-06T18:52:04.083058Z",
     "iopub.status.idle": "2022-12-06T18:52:04.094967Z",
     "shell.execute_reply": "2022-12-06T18:52:04.093930Z",
     "shell.execute_reply.started": "2022-12-06T18:52:04.083394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520952, 130239)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, char_index: Char_Index, label_index: Label_Index) -> None:\n",
    "        self.df = df\n",
    "        self.char_index = char_index\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        url = self.df.url[index]\n",
    "        label = self.label_index(self.df.type[index])\n",
    "        return torch.tensor(self.char_index.string_indexes(url)), torch.tensor(label)\n",
    "\n",
    "trainDataset = Dataset(train_data, char_index, label_index)\n",
    "testDataset = Dataset(test_data, char_index, label_index)\n",
    "len(trainDataset), len(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:52:04.097659Z",
     "iopub.status.busy": "2022-12-06T18:52:04.096474Z",
     "iopub.status.idle": "2022-12-06T18:52:04.267795Z",
     "shell.execute_reply": "2022-12-06T18:52:04.266717Z",
     "shell.execute_reply.started": "2022-12-06T18:52:04.097624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[62, 13,  4,  ...,  0,  0,  0],\n",
      "        [19, 20, 20,  ...,  0,  0,  0],\n",
      "        [26, 26, 26,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 0,  7,  1,  ...,  0,  0,  0],\n",
      "        [ 0,  5,  6,  ...,  0,  0,  0],\n",
      "        [26, 26, 26,  ...,  0,  0,  0]]) tensor([1, 3, 1, 1, 1, 1, 0, 1, 0, 2, 1, 0, 0, 1, 1, 1, 0, 3, 1, 0, 2, 1, 1, 2,\n",
      "        2, 0, 1, 2, 0, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 3, 1, 1, 1, 0, 1, 0, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 3, 1, 1, 0,\n",
      "        1, 1, 2, 1, 1, 0, 1, 3, 1, 1, 2, 1, 2, 0, 1, 1, 3, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 3, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 3, 1, 1, 0, 2, 1, 1,\n",
      "        1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 2, 0, 0, 1, 0, 2, 1, 1, 1, 1, 1,\n",
      "        1, 2, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1,\n",
      "        1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    urls, labels = zip(*batch)\n",
    "    urls = nn.utils.rnn.pad_sequence(urls, batch_first=True)\n",
    "    return urls, torch.tensor(labels)\n",
    "\n",
    "trainGenerator = torch.utils.data.DataLoader(trainDataset, batch_size=256, shuffle=True, collate_fn=collate_fn, num_workers = 2)\n",
    "testGenerator = torch.utils.data.DataLoader(testDataset, batch_size=256, shuffle=True, collate_fn=collate_fn, num_workers = 2)\n",
    "for inputs, labels in trainGenerator:\n",
    "    print(inputs, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:52:04.271497Z",
     "iopub.status.busy": "2022-12-06T18:52:04.271203Z",
     "iopub.status.idle": "2022-12-06T18:52:05.659495Z",
     "shell.execute_reply": "2022-12-06T18:52:05.658396Z",
     "shell.execute_reply.started": "2022-12-06T18:52:04.271467Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2571,  0.1513,  0.3357, -0.1672],\n",
       "        [ 0.2781,  0.1040,  0.0853, -0.1624],\n",
       "        [ 0.3079,  0.2533,  0.2197, -0.6255],\n",
       "        ...,\n",
       "        [ 0.4140,  0.0814,  0.5379, -0.4283],\n",
       "        [ 0.4566, -0.0758,  0.3949, -0.3915],\n",
       "        [ 0.3127,  0.1790,  0.1862, -0.6998]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, output_size, num_layers=1, dropout=0.2, bidirectional=False):\n",
    "        super(GRU, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True, bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)   # [batch_size, seq_len] -> [batch_size, seq_len, embedding_size]\n",
    "        if self.bidirectional == True:\n",
    "            h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)   # [num_layers*2, batch_size, hidden_size]\n",
    "        else:\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # [num_layers, batch_size, hidden_size]\n",
    "        out, _ = self.gru(x, h0)    # [batch_size, seq_len, hidden_size]\n",
    "        if self.bidirectional == True:\n",
    "            out = out[:, -1, :self.hidden_size] + out[:, 0, self.hidden_size:]  # [batch_size, hidden_size]\n",
    "        return self.fc(out)\n",
    "gru_model = GRU(len(char_index.char_index), 128, 128, len(label_index.labels), bidirectional=True, num_layers=1)\n",
    "gru_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:52:05.661523Z",
     "iopub.status.busy": "2022-12-06T18:52:05.661061Z",
     "iopub.status.idle": "2022-12-06T18:52:05.667399Z",
     "shell.execute_reply": "2022-12-06T18:52:05.666343Z",
     "shell.execute_reply.started": "2022-12-06T18:52:05.661485Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(gru_model.parameters(), lr=0.001)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T18:52:05.671403Z",
     "iopub.status.busy": "2022-12-06T18:52:05.670998Z",
     "iopub.status.idle": "2022-12-06T19:13:17.326069Z",
     "shell.execute_reply": "2022-12-06T19:13:17.324943Z",
     "shell.execute_reply.started": "2022-12-06T18:52:05.671367Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2035/2035 [01:55<00:00, 17.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 0.152655381333147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.08903452890883026, test acc: 0.9716214037269942\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2035/2035 [01:56<00:00, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train loss: 0.06994125512256961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.06669379950799267, test acc: 0.9792074570597133\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2035/2035 [01:53<00:00, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train loss: 0.05602555510150932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.06256626188491557, test acc: 0.9802056219719132\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2035/2035 [01:55<00:00, 17.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train loss: 0.04785536868630449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.0600509934625012, test acc: 0.9809043374104531\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2035/2035 [01:56<00:00, 17.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, train loss: 0.04245174165233896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2035/2035 [01:56<00:00, 17.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train loss: 0.038177085626659876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.05500464021522837, test acc: 0.9833229677746297\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2035/2035 [01:56<00:00, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, train loss: 0.03147784808549929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.0548662106124117, test acc: 0.9831617257503513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2035/2035 [01:55<00:00, 17.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, train loss: 0.028985044042893322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.056610636177064744, test acc: 0.9837222337395096\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2035/2035 [01:56<00:00, 17.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train loss: 0.02633294252294324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.057617524689089046, test acc: 0.9834381406491143\n"
     ]
    }
   ],
   "source": [
    "best_right = 0\n",
    "early_stop = 0\n",
    "gru_model.to('cuda')\n",
    "for epoch in range(epochs):\n",
    "    loss_value = 0.0\n",
    "    gru_model.train()\n",
    "    for inputs, label in tqdm(trainGenerator):\n",
    "        inputs = inputs.cuda()\n",
    "        label = label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = gru_model(inputs)\n",
    "        l = loss(output, label)\n",
    "        l.backward()\n",
    "        loss_value += l.item()\n",
    "        optimizer.step()\n",
    "    print(f'epoch: {epoch+1}, train loss: {loss_value/len(trainGenerator)}')\n",
    "\n",
    "    # eval\n",
    "    gru_model.cuda()\n",
    "    gru_model.eval()\n",
    "    loss_value = 0.0\n",
    "    right_num = 0\n",
    "    for inputs, label in testGenerator:\n",
    "        inputs = inputs.cuda()\n",
    "        label = label.cuda()\n",
    "        output = gru_model(inputs)\n",
    "        l = loss(output, label)\n",
    "        loss_value += l.item()\n",
    "        right_num += (torch.argmax(output, dim=1) == label).sum().item()\n",
    "    print(f'\\t test loss: {loss_value/len(testGenerator)}, test acc: {right_num/len(testDataset)}')\n",
    "    \n",
    "    # save model or early stop\n",
    "    if right_num > best_right:\n",
    "        best_right = right_num\n",
    "        torch.save(gru_model.state_dict(), './gru_model.pth')\n",
    "        print('save model')\n",
    "        early_stop = 0\n",
    "    else:\n",
    "        early_stop += 1\n",
    "        if early_stop > 3:\n",
    "            print('early stop')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
